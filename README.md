# Validating the Llama 3.2 1B Instruct Model on the MATH Dataset

<img width="1411" alt="image" src="https://github.com/user-attachments/assets/0bda4bc7-c3ed-401e-96be-b0716db92826">

<img width="1415" alt="image" src="https://github.com/user-attachments/assets/de202dc0-59c5-4b73-a8cb-47c95f6e8005">

## References

- [Reported evaluation results by Meta for Llama 3.2 1B Instruct](https://huggingface.co/datasets/meta-llama/Llama-3.2-1B-Instruct-evals)
- [Extracting boxed final answers and evaluating exact match](https://github.com/meta-llama/llama-cookbook/blob/2501f519c7a775e3fab82ff286916671023ca9c6/tools/benchmarks/llm_eval_harness/meta_eval/meta_template/math_hard/utils.py)
